import sys
import chess
import torch
import numpy as np
from copy import deepcopy
from multiprocessing import Pool, cpu_count
from typing import List, Dict, Tuple
import time
import threading
from queue import Queue
import asyncio
from collections import OrderedDict
from threading import Event
from collections import deque

from core.model import ChessNet
from core.chess_base import ChessEnv

class MCTSNode:
    _id_counter = 0  # Class variable to keep track of node IDs
    
    def __init__(self, board: chess.Board, env, parent=None, move=None):
        self.id = MCTSNode._id_counter
        MCTSNode._id_counter += 1
        self.board = board
        self.env = env
        self.parent = parent
        self.move = move
        self.children = []
        self.visits = 0
        self.value_sum = 0
        self.prior = 0
        self.is_expanded = False
        self.virtual_loss = 0
        self.value = 0
        self.lock = threading.Lock()  # Lock cho má»—i node

    def get_value(self):
        with self.lock:
            if self.visits + self.virtual_loss == 0:
                return 0
            return self.value_sum / (self.visits + self.virtual_loss)

    def add_virtual_loss(self):
        with self.lock:
            self.virtual_loss += 3

    def revert_virtual_loss(self):
        with self.lock:
            self.virtual_loss = max(0, self.virtual_loss - 3)

    @property
    def is_terminal(self):
        return self.board.is_game_over()

class LRUCache:
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = OrderedDict()
        self.lock = threading.Lock()

    def get(self, key):
        with self.lock:
            if key not in self.cache:
                return None
            self.cache.move_to_end(key)
            return self.cache[key]

    def put(self, key, value):
        with self.lock:
            if key in self.cache:
                self.cache.move_to_end(key)
            self.cache[key] = value
            if len(self.cache) > self.capacity:
                self.cache.popitem(last=False)

class MCTS:
    def __init__(self, neural_net, converter, env, c_puct=1.0, simulations=100,
                 max_depth=50, device='cpu', num_processes=None, use_model=False,
                 temperature=1.0):
        self.neural_net = neural_net
        self.converter = converter
        self.env = env
        self.c_puct = c_puct
        self.simulations = simulations
        self.max_depth = max_depth
        self.device = device
        self.use_model = use_model
        self.temperature = temperature
        self.root = None  # LÆ°u root node Ä‘á»ƒ reuse

        # Khá»Ÿi táº¡o process pool vÃ  thread pool
        if num_processes is None:
            num_processes = cpu_count()
        self.num_processes = num_processes
        self.pool = Pool(processes=num_processes)
        
        # Thread pool cho async inference
        self.thread_pool = []
        self.inference_queue = Queue()
        self.result_queue = Queue()
        self.lock = threading.Lock()
        
        # Cache cho neural network predictions
        self.prediction_cache = {}

    def __del__(self):
        self.pool.close()
        self.pool.join()
        for thread in self.thread_pool:
            thread.join()

    def run(self, root_board: chess.Board):
        # Reuse root node náº¿u cÃ³
        if self.root is not None:
            # TÃ¬m child node tÆ°Æ¡ng á»©ng vá»›i nÆ°á»›c Ä‘i vá»«a thá»±c hiá»‡n
            for child in self.root.children:
                if child.board == root_board:
                    self.root = child
                    break
                else:
                    # Náº¿u khÃ´ng tÃ¬m tháº¥y, táº¡o root má»›i
                    self.root = MCTSNode(root_board, self.env)
        else:
            self.root = MCTSNode(root_board, self.env)

        # Khá»Ÿi táº¡o thread pool náº¿u chÆ°a cÃ³
        if not self.thread_pool:
            for _ in range(self.num_processes):
                thread = threading.Thread(target=self._inference_worker)
                thread.daemon = True
                thread.start()
                self.thread_pool.append(thread)

        # Thá»±c hiá»‡n simulations láº§n
        for _ in range(self.simulations):
            try:
                # 1. Select: Chá»n node Ä‘á»ƒ má»Ÿ rá»™ng
                node, path = self._select(self.root)
                
                # 2. Expand: Má»Ÿ rá»™ng node Ä‘Ã£ chá»n
                if not node.is_terminal:
                    self._expand(node)
                
                # 3. Simulate: MÃ´ phá»ng tá»« node Ä‘Ã£ má»Ÿ rá»™ng
                value = self._simulate(node)
                
                # 4. Backprop: Cáº­p nháº­t thÃ´ng tin ngÆ°á»£c lÃªn
                self._backprop(node, value)
            except Exception as e:
                print(f"Error in MCTS simulation: {str(e)}")
                continue
            finally:
                # Revert virtual loss cho táº¥t cáº£ nodes trong path
                if 'path' in locals():  # Kiá»ƒm tra xem path cÃ³ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a khÃ´ng
                    for node in path:
                        node.revert_virtual_loss()

        # TÃ­nh xÃ¡c suáº¥t cho cÃ¡c nÆ°á»›c Ä‘i
        move_probs = self._get_move_probs(root_board)
        return move_probs

    def _select(self, node: MCTSNode) -> Tuple[MCTSNode, List[MCTSNode]]:
        """
        Chá»n node Ä‘á»ƒ má»Ÿ rá»™ng dá»±a trÃªn UCB.
        
        Returns:
            Tuple[MCTSNode, List[MCTSNode]]: (node Ä‘Æ°á»£c chá»n, path tá»« root Ä‘áº¿n node Ä‘Ã³)
        """
        path = []  # LÆ°u láº¡i path Ä‘á»ƒ revert virtual loss náº¿u cáº§n
        while node.is_expanded and not node.is_terminal:
            path.append(node)
            node.add_virtual_loss()  # ThÃªm virtual loss khi Ä‘i xuá»‘ng
            
            # TÃ­nh UCB cho má»—i child
            ucb_values = []
            for child in node.children:
                # UCB = Q + U
                # Q = value
                # U = c_puct * P * sqrt(N) / (1 + n)
                Q = child.get_value()
                U = self.c_puct * child.prior * np.sqrt(node.visits) / (1 + child.visits)
                ucb_values.append(Q + U)
            
            # Chá»n child cÃ³ UCB cao nháº¥t
            best_child_idx = np.argmax(ucb_values)
            node = node.children[best_child_idx]
        
        path.append(node)  # ThÃªm node cuá»‘i cÃ¹ng vÃ o path
        return node, path

    def _expand(self, node: MCTSNode):
        """Má»Ÿ rá»™ng node báº±ng cÃ¡ch thÃªm cÃ¡c children."""
        if not node.is_expanded:
            # Táº¡o children cho má»—i nÆ°á»›c Ä‘i há»£p lá»‡
            for move in node.board.legal_moves:
                # Táº¡o báº£n sao hoÃ n chá»‰nh cá»§a mÃ´i trÆ°á»ng
                child_env = deepcopy(self.env)
                child_env.chess_board = node.board.copy()
                child_env.chess_board.push(move)
                
                # Cáº­p nháº­t board_deltas cho child_env
                child_env.board_deltas = deque(maxlen=8)
                child_env.board_deltas.appendleft(np.copy(child_env.board))
                
                # Táº¡o node con vá»›i mÃ´i trÆ°á»ng má»›i
                child = MCTSNode(child_env.chess_board, child_env, parent=node, move=move)
                node.children.append(child)
            
            # Láº¥y policy vÃ  value tá»« neural network cho node hiá»‡n táº¡i
            state = node.env._observation()
            mask = self._legal_moves_mask(node.board)
            
            # ThÃªm vÃ o inference queue
            self.inference_queue.put((state, mask))
            
            # Láº¥y káº¿t quáº£ tá»« result queue
            policy, value = self.result_queue.get()
            
            # Cáº­p nháº­t prior vÃ  value cho táº¥t cáº£ children
            for child in node.children:
                child.prior = policy[self.converter.move_to_index(child.move)]
                child.value = value  # LÆ°u value prediction
            
            node.is_expanded = True

    def _simulate(self, node: MCTSNode) -> float:
        """MÃ´ phá»ng tá»« node Ä‘áº¿n khi káº¿t thÃºc game hoáº·c sá»­ dá»¥ng value prediction."""
        if self.use_model:
            # Sá»­ dá»¥ng neural network Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tráº¡ng thÃ¡i
            state = node.env._observation()
            mask = self._legal_moves_mask(node.board)
            
            # ThÃªm vÃ o inference queue
            self.inference_queue.put((state, mask))
            
            # Láº¥y káº¿t quáº£ tá»« result queue
            _, value = self.result_queue.get()
            return float(value)
        else:
            # Rollout Ä‘áº¿n cuá»‘i game
            board = node.board.copy()
            current_depth = 0
            
            while not board.is_game_over() and current_depth < self.max_depth:
                legal_moves = list(board.legal_moves)
                if not legal_moves:
                    break
                    
                move = np.random.choice(legal_moves)
                board.push(move)
                current_depth += 1
            
            # Tráº£ vá» káº¿t quáº£ game
            result = board.result()
            if result == "1-0":
                return 1.0
            elif result == "0-1":
                return -1.0
            else:
                return 0.0

    def _backprop(self, node: MCTSNode, value: float):
        """Cáº­p nháº­t thÃ´ng tin ngÆ°á»£c lÃªn cÃ¢y."""
        while node is not None:
            with self.lock:
                node.visits += 1
                node.value_sum += value
            value = -value  # Äáº£o ngÆ°á»£c giÃ¡ trá»‹ cho ngÆ°á»i chÆ¡i khÃ¡c
            node = node.parent

    def _inference_worker(self):
        """Worker thread cho async inference."""
        while True:
            state, mask = self.inference_queue.get()
            
            # Convert to tensors
            state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(self.device)
            mask_tensor = torch.from_numpy(mask).float().unsqueeze(0).to(self.device)
            
            # Get prediction from model
            with torch.no_grad():
                policy, value = self.neural_net(state_tensor, mask_tensor)
                policy = policy.squeeze().cpu().numpy()
                value = value.squeeze().cpu().numpy()
            
            # Put result back
            self.result_queue.put((policy, value))

    def _legal_moves_mask(self, board: chess.Board) -> np.ndarray:
        """Táº¡o mask cho cÃ¡c nÆ°á»›c Ä‘i há»£p lá»‡."""
        mask = np.zeros(self.env.action_dim, dtype=np.float32)
        for move in board.legal_moves:
            idx = self.converter.move_to_index(move)
            mask[idx] = 1
        return mask
    
    def _revert_virtual_loss_path(self, node: MCTSNode):
        """
        Revert virtual loss cho táº¥t cáº£ nodes trong path tá»« node hiá»‡n táº¡i lÃªn root.
        
        Args:
            node: Node hiá»‡n táº¡i cáº§n revert virtual loss
        """
        current = node
        while current is not None:
            current.revert_virtual_loss()
            current = current.parent

    def _get_move_probs(self, root_board: chess.Board) -> np.ndarray:
        """
        TÃ­nh xÃ¡c suáº¥t cho cÃ¡c nÆ°á»›c Ä‘i dá»±a trÃªn sá»‘ láº§n thÄƒm cá»§a má»—i node.
        
        Args:
            root_board: BÃ n cá» hiá»‡n táº¡i
            
        Returns:
            np.ndarray: Máº£ng xÃ¡c suáº¥t cho má»—i nÆ°á»›c Ä‘i
        """
        move_probs = np.zeros(self.env.action_dim)
        total_visits = sum(child.visits for child in self.root.children)

        if total_visits > 0:
            for child in self.root.children:
                idx = self.converter.move_to_index(child.move)
                move_probs[idx] = child.visits / total_visits

            # ThÃªm Dirichlet noise cho root node
            legal_moves = list(root_board.legal_moves)
            noise_probs = np.zeros_like(move_probs)
            noise = np.random.dirichlet([0.3] * len(legal_moves))

            for i, move in enumerate(legal_moves):
                idx = self.converter.move_to_index(move)
                noise_probs[idx] = noise[i]

            # Mix vá»›i tá»· lá»‡ 75-25
            move_probs = 0.75 * move_probs + 0.25 * noise_probs

            # Apply temperature
            if self.temperature != 1.0:
                move_probs = np.power(move_probs, 1.0 / self.temperature)
                move_probs /= np.sum(move_probs)

            # Normalize
            if np.sum(move_probs) > 0:
                move_probs /= np.sum(move_probs)

        return move_probs

def load_predict_model(path: str, model: ChessNet, device: str = "cuda"):
    """
    Load model chá»‰ Ä‘á»ƒ predict, khÃ´ng cáº§n load optimizer vÃ  scheduler.
    HÃ m nÃ y nháº¹ hÆ¡n vÃ  nhanh hÆ¡n load_training_model.
    
    Args:
        path: ÄÆ°á»ng dáº«n tá»›i file checkpoint
        model: Instance cá»§a model cáº§n load weights vÃ o
        device: Device Ä‘á»ƒ load model (cuda/cpu)
    
    Returns:
        ChessNet: Model Ä‘Ã£ load weights
    """
    try:
        # Load vá»›i map_location Ä‘á»ƒ cÃ³ thá»ƒ load model tá»« GPU sang CPU hoáº·c ngÆ°á»£c láº¡i
        checkpoint = torch.load(path, map_location=device)
        
        # Load model state
        if isinstance(model, torch.nn.DataParallel):
            model.module.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint['model_state_dict'])
        
        # Chuyá»ƒn model sang device phÃ¹ há»£p
        model = model.to(device)
        
        # Chuyá»ƒn sang eval mode
        model.eval()
        
        print(f"âœ… Loaded model for prediction from {path}")
        if 'loss' in checkpoint:
            print(f"   â””â”€â”€ Model loss: {checkpoint['loss']:.4f}")
        
        return model
        
    except Exception as e:
        print(f"âŒ Error loading model for prediction: {str(e)}")
        raise

if __name__ == "__main__":
    # Khá»Ÿi táº¡o device
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # Khá»Ÿi táº¡o vÃ  load model
    model = ChessNet()
    model = load_predict_model(r"model_checkpoint\best_model.pth", model)
    model.to(device)
    model.eval()

    # Khá»Ÿi táº¡o mÃ´i trÆ°á»ng
    env = ChessEnv()
    env.reset()

    # Khá»Ÿi táº¡o MCTS vá»›i model Ä‘Ã£ load
    mcts = MCTS(
        neural_net=model,
        converter=env.chess_coords,
        env=env,
        simulations=400,  # TÄƒng sá»‘ lÆ°á»£t mÃ´ phá»ng Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t hÆ¡n
        max_depth=50,     # Äá»™ sÃ¢u tá»‘i Ä‘a cho má»—i mÃ´ phá»ng
        device=device,
        num_processes=4,  # Sá»‘ process cho parallel search
        use_model=True,    # Sá»­ dá»¥ng model Ä‘á»ƒ dá»± Ä‘oÃ¡n nÆ°á»›c Ä‘i
        temperature=1.0    # KhÃ´ng sá»­ dá»¥ng temperature
    )

    move_count = 0
    print("ğŸ® Báº¯t Ä‘áº§u game tá»± Ä‘Ã¡nh...")

    while not env.is_game_over():
        # In tráº¡ng thÃ¡i bÃ n cá»
        print("\n" + str(env.chess_board))
        
        # Cháº¡y MCTS Ä‘á»ƒ tÃ¬m nÆ°á»›c Ä‘i tá»‘t nháº¥t
        pi = mcts.run(env.chess_board)
        
        # Chá»n nÆ°á»›c Ä‘i dá»±a trÃªn policy tá»« MCTS
        valid_moves = env.legal_actions
        pi_valid = pi * valid_moves
        
        if np.sum(pi_valid) > 0:
            if move_count < 30:  # Temperature = 1 cho 30 nÆ°á»›c Ä‘áº§u
                pi_valid = pi_valid / np.sum(pi_valid)
                action = np.random.choice(len(pi), p=pi_valid)
            else:  # Temperature = 0 (greedy) sau 30 nÆ°á»›c
                action = np.argmax(pi_valid)
        else:
            action = np.random.choice(np.where(valid_moves)[0])

        # Thá»±c hiá»‡n nÆ°á»›c Ä‘i
        move_uci = env.chess_coords.index_to_move(action)
        print(f"Move {move_count+1}: {move_uci} (policy: {pi[action]:.4f})")
        
        env.step(action)
        move_count += 1
        break

    # In káº¿t quáº£ game
    result = env.chess_board.result()
    print(f"\nğŸ Game káº¿t thÃºc sau {move_count} nÆ°á»›c Ä‘i")
    print(f"Káº¿t quáº£: {result}")