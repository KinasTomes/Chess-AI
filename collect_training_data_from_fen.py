import os
import chess
import chess.pgn
import chess.engine
import numpy as np
import ray
import torch

from typing import Dict
from training.timer import Timer
from core.chess_base import ChessEnv
from training.replay_buffer import ReplayBuffer
from core.coords_converter import ChessCoordsConverter
from utils.stockfish_worker import StockfishWorker, parallel_evaluate_legal_moves

stockfish_path = r'evaluation\stockfish\stockfish-windows-x86-64-avx2.exe'

def split_pgn_file(input_pgn_path: str, nums_game: int, output_dir: str = None) -> None:
    """
    TÃ¡ch má»™t file PGN lá»›n thÃ nh cÃ¡c file PGN nhá», má»—i file chá»©a má»™t vÃ¡n cá».

    Args:
        input_pgn_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file PGN gá»‘c.
        output_dir (str): ThÆ° má»¥c Ä‘á»ƒ lÆ°u cÃ¡c file PGN nhá».
    """
    if not output_dir is None and not os.path.exists(output_dir):
        os.makedirs(output_dir)

    with open(input_pgn_path, encoding='utf-8') as pgn_file:
        game_idx = 1
        while game_idx < nums_game:
            game = chess.pgn.read_game(pgn_file)
            if game is None:
                break

            if output_dir is None:
                output_path = f"game_{game_idx}.pgn"
            else:
                output_path = os.path.join(output_dir, f"game_{game_idx}.pgn")

            
            with open(output_path, 'w', encoding='utf-8') as output_file:
                exporter = chess.pgn.StringExporter(headers=True, variations=True, comments=True)
                output_file.write(game.accept(exporter))
            print(f"âœ… Saved game {game_idx} to {output_path}")
            game_idx += 1

    print(f"\nğŸ¯ Tá»•ng cá»™ng {game_idx - 1} vÃ¡n Ä‘Ã£ Ä‘Æ°á»£c tÃ¡ch vÃ  lÆ°u trong thÆ° má»¥c '{output_dir}'.")

def get_fen_and_moves_from_pgn_file(pgn_path: str) -> tuple[list[str], list[str]]:
    with open(pgn_path, 'r', encoding='utf-8') as pgn_file:
        game = chess.pgn.read_game(pgn_file)
        if game is None:
            print("âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c vÃ¡n cá».")
            return [], []

        board = game.board()
        fen_list = []
        uci_moves = []

        for move in game.mainline_moves():
            fen_list.append(board.fen())
            uci_moves.append(move.uci())
            board.push(move)

        return fen_list, uci_moves
    
def map_legal_move_scores_to_policy(legal_moves: Dict[str, float], action_dim: int = 4864) -> np.ndarray:
    policy = np.zeros(action_dim, dtype=np.float32)
    converter = ChessCoordsConverter()
    for move_uci, score in legal_moves.items():
        move_index = converter.move_to_index(chess.Move.from_uci(move_uci))
        policy[move_index] = score
    return policy
    
def get_replay_buffer_from_pgn(pgn_path: str) -> ReplayBuffer:
    # Khá»Ÿi táº¡o Ray
    ray.init(num_cpus=8)
    
    # Khá»Ÿi táº¡o cÃ¡c worker
    num_workers = 8  # Sá»‘ worker báº±ng sá»‘ CPU cores
    workers = [StockfishWorker.remote(stockfish_path) for _ in range(num_workers)]
    
    try:
        fens, moves = get_fen_and_moves_from_pgn_file(pgn_path)
        w, b = (1, 2) if chess.Board(fens[0]).turn else (2, 1)
        env = ChessEnv(white_player_id=w, black_player_id=b)
        replay_buffer = ReplayBuffer()
        game_history = []

        for move in moves:
            scores = parallel_evaluate_legal_moves(env.chess_board, workers)
            game_history.append({
                'state': env._observation(),
                'policy': map_legal_move_scores_to_policy(scores),
                'player': env.to_play
            })
            env.step(env.chess_coords.move_to_index(chess.Move.from_uci(move)))

        if env.winner == env.white_player:
            game_result = 1
        elif env.winner == env.black_player:
            game_result = -1    
        else:
            game_result = 0

        for history in game_history:
            if history['player'] == env.white_player:
                value = game_result
            else:
                value = -game_result

            replay_buffer.add_game([(history['state'], history['policy'], value)])
        
        return replay_buffer
        
    finally:
        # Táº¯t cÃ¡c worker
        for worker in workers:
            worker.shutdown.remote()
        # Táº¯t Ray
        ray.shutdown()

def process_pgn_directory_to_buffer(directory_path: str, save_dir: str = "buffer_data", samples_per_file: int = 10000) -> None:
    """
    Xá»­ lÃ½ táº¥t cáº£ cÃ¡c file PGN trong thÆ° má»¥c vÃ  lÆ°u thÃ nh cÃ¡c file buffer.

    Args:
        directory_path: ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a cÃ¡c file PGN
        save_dir: ThÆ° má»¥c Ä‘á»ƒ lÆ°u cÃ¡c file buffer
        samples_per_file: Sá»‘ samples tá»‘i Ä‘a trong má»—i file buffer
    """
    # Táº¡o thÆ° má»¥c lÆ°u náº¿u chÆ°a tá»“n táº¡i
    os.makedirs(save_dir, exist_ok=True)
    
    # Láº¥y danh sÃ¡ch cÃ¡c file PGN
    pgn_files = [f for f in os.listdir(directory_path) if f.endswith('.pgn')]
    print(f"ğŸ¯ TÃ¬m tháº¥y {len(pgn_files)} file PGN trong thÆ° má»¥c {directory_path}")
    
    # Khá»Ÿi táº¡o Ray vÃ  cÃ¡c worker
    ray.init(num_cpus=8)
    num_workers = 8
    workers = [StockfishWorker.remote(stockfish_path) for _ in range(num_workers)]
    
    try:
        # Buffer táº¡m thá»i Ä‘á»ƒ gom samples
        temp_buffer = ReplayBuffer()
        current_part = 0
        
        # Xá»­ lÃ½ tá»«ng file PGN
        for pgn_file in pgn_files:
            print(f"\nğŸ“‚ Äang xá»­ lÃ½ file: {pgn_file}")
            pgn_path = os.path.join(directory_path, pgn_file)
            
            # Äá»c file PGN
            with open(pgn_path, 'r', encoding='utf-8') as pgn_file:
                game = chess.pgn.read_game(pgn_file)
                if game is None:
                    print(f"âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c vÃ¡n cá» tá»« file {pgn_path}")
                    continue

                board = game.board()
                moves = list(game.mainline_moves())
                
                # XÃ¡c Ä‘á»‹nh ngÆ°á»i chÆ¡i
                w, b = (1, 2) if board.turn else (2, 1)
                env = ChessEnv(white_player_id=w, black_player_id=b)
                game_history = []

                # Xá»­ lÃ½ tá»«ng nÆ°á»›c Ä‘i
                for move in moves:
                    # ÄÃ¡nh giÃ¡ cÃ¡c nÆ°á»›c Ä‘i há»£p lá»‡
                    scores = parallel_evaluate_legal_moves(env.chess_board, workers)
                    
                    # LÆ°u tráº¡ng thÃ¡i vÃ  policy
                    game_history.append({
                        'state': env._observation(),
                        'policy': map_legal_move_scores_to_policy(scores),
                        'player': env.to_play
                    })
                    
                    # Thá»±c hiá»‡n nÆ°á»›c Ä‘i
                    env.step(env.chess_coords.move_to_index(move))

                # XÃ¡c Ä‘á»‹nh káº¿t quáº£ vÃ¡n Ä‘áº¥u
                if env.winner == env.white_player:
                    game_result = 1
                elif env.winner == env.black_player:
                    game_result = -1    
                else:
                    game_result = 0

                # ThÃªm vÃ o buffer
                temp_game_data = []
                for history in game_history:
                    if history['player'] == env.white_player:
                        value = game_result
                    else:
                        value = -game_result

                    temp_game_data.append((history['state'], history['policy'], value))
                    
                temp_buffer.add_game(temp_game_data)
                # Kiá»ƒm tra xem cÃ³ Ä‘á»§ samples Ä‘á»ƒ lÆ°u file má»›i khÃ´ng
                if len(temp_buffer) >= samples_per_file:
                    # Láº¥y samples_per_file samples Ä‘áº§u tiÃªn
                    states, policies, values = temp_buffer.sample_batch(samples_per_file)
                    
                    # LÆ°u thÃ nh file riÃªng
                    save_path = os.path.join(save_dir, f"buffer_part_{current_part}.pt")
                    torch.save({
                        'states': states,
                        'policies': policies,
                        'values': values
                    }, save_path)
                    print(f"ğŸ’¾ ÄÃ£ lÆ°u file {save_path} vá»›i {len(states)} samples")
                    
                    # XÃ³a samples Ä‘Ã£ lÆ°u khá»i buffer
                    temp_buffer.clear(10000)
                    current_part += 1
        
        # LÆ°u pháº§n samples cÃ²n láº¡i náº¿u cÃ³
        if len(temp_buffer) > 0:
            states, policies, values = temp_buffer.sample_batch(len(temp_buffer))
            save_path = os.path.join(save_dir, f"buffer_part_{current_part}.pt")
            torch.save({
                'states': states,
                'policies': policies,
                'values': values
            }, save_path)
            print(f"ğŸ’¾ ÄÃ£ lÆ°u file {save_path} vá»›i {len(states)} samples")
            
    finally:
        # Táº¯t cÃ¡c worker
        for worker in workers:
            worker.shutdown.remote()
        # Táº¯t Ray
        ray.shutdown()

if __name__ == "__main__":
    timer = Timer()
    timer.start()
    
    split_pgn_file(
        input_pgn_path=r'sample_data\ficsgamesdb_2024_chess2000.pgn',
        nums_game=2001,
        output_dir=r'sample_data\ficsgame_2024_chess2000'
    )
    
    timer.end()